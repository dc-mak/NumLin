\section{Discussion and Related Work}\label{sec:discussion_related_work}

\subsection{Finding Bugs in SymPy's Output}\label{subsec:finding_bugs}

Prior to this project, we had little experience with linear algebra libraries
or the problem of matrix expression compilation. As such, we based our initial
\lang\ implementation of a Kalman filter using BLAS and LAPACK, on a popular
GitHub gist of a Fortran implementation, one that was \emph{automatically
generated} from SymPy's matrix expression compiler~\cite{rocklin_thesis}.

Once we translated the implementation from Fortran to \lang, we attempted to
compile it and found that (to our surprise) it did not type-check. This was
because the original implementation contained incorrect aliasing, unused
variables and unnecessary temporaries, and did not adhere to Fortran's
read/write permissions (with respect to \texttt{intent} annotations
\texttt{in}, \texttt{out} and \texttt{inout}) all of which were now highlighted
by \lang's type system.

The original implementation used 6 temporaries, one of which was immediately
spotted as never being used due to linearity. It also contained two variables
which were marked as \texttt{intent(in)} but would have been written over by
calls to `gemm', spotted by the fractional capabilities feature. Furthermore,
it used a matrix \emph{twice} in a call to `symm', once with a read permission
but once with a \emph{write} permission.  Fortran assumes that any parameter
being written to is not aliased and so this call was not only incorrect, but
illegal according to the standard, both aspects of which were captured by
linearity and fractional capabilities.

Lastly, it contained another unnecessary temporary, however one that was not
obvious without linear types. To spot it, we first performed live-range
splitting (checked by linearity) by hoisting calls to \highl{freeM} and then
annotated the freed matrices with their dimensions.  After doing so and
spotting two disjoint live-ranges of the same size, we replaced a call to
\highl{freeM} followed by allocating call to \highl{copy} with one, in-place
call to \highl{copyM_to}. We believe the ability to boldly refactor code which
manages memory is good evidence of the usefulness of linearity as a tool for
programming.

\subsection{Related Work}

Using linear types for BLAS routines is a particularly good domain fit (given
the implicit restrictions on aliasing arguments), and as a result the idea of
using substructural types to express array computations is not a particularly
new one~\cite{scholz,henriksen,bernardy2016}.  However, many of these designs
have been focused on building languages to \emph{implement} the kernel linear
algebra functions, and as a result, they tend to add additional limitations on
the language design. Both Futhark~\cite{henriksen} and Single Assignment
C~\cite{scholz} omit higher-order functions to facilitate compilation to GPUs.
The work of \cite{bernardy2016} forbids term-level recursion, in order to
ensure that all higher-order computations can be statically normalized away and
thereby maximize opportunities for array fusion.

In contrast, our approach is to begin with the assumption that we can take
existing efficient BLAS-like libraries, and then enforce their correct
\emph{usage} using a linear type discipline with fractional permissions. 

This approach is similar to the one taken in linear algebra libraries for Rust
-- these libraries typically take advantage of the distinction that Rust's type
system offers between mutable views/references to arrays.  The work of
\cite{weiss} and \cite{rustbelt} suggest that Rust's borrow-checker \emph{can
be expressed in simpler terms} using fractional permissions, though to our
knowledge the programmer-visible lifetime analysis in Rust has never been
formalized.

Working explicitly with fractional permissions has two main benefits. First,
our type system demonstrates that type systems for fractional permissions can
be dramatically simpler than existing state-of-the-art approaches, including
both industrial languages like Rust, as well as academic (such as those
developed by \cite{bierhoff}).  Bierhoff \emph{et al}'s type system, much like
Rust's, builds a complex dataflow analysis into the typing rules to infer when
variables can be shared or not. This allows for more natural-looking user
programs, but can create the impression that using fractional permissions
requires a heavy theoretical and engineering effort going well beyond that
needed for supporting basic linear types.

Instead, our approach, of requiring sharing to be made explicit, lets us
demonstrate that the existing unification machinery already in place for
ordinary ML-style type inference can be reused to support fractions. Basically,
we can view sharing a value as dividing a fraction by two, and after taking
logarithms all fractions are Peano numbers, whose equality can be established
with ordinary unification.

This fact is important because there are major upcoming implementations of
linear types such as Linear Haskell~\cite{bernardy2017linear}, which do not
have built-in support for fractional permissions. Instead, Linear Haskell takes
a slightly different definition of linearity, one based on \emph{arrows} as
opposed to \emph{kinds}: for $f : a \multimap b$, if $f u$ is used exactly once
\emph{then} $u$ is used exactly once. Whilst this has the advantage of being
backwards-compatible, it also means that the type system has no built-in
support for the concurrent reader, exclusive writer pattern that fractional
permissions enable.

However, since our type system shows demonstrates unification is ``all one
needs'' for fractions, it should be possible to \emph{encode} \lang's approach
to fractional permissions in Linear Haskell by adding a GADT-style natural
number index to array types tracking the fraction, which should enable
supporting high-performance BLAS bindings in Linear Haskell. Actually
implementing this is something we leave for future work, as there remains one
issue which we do not see a good encoding for. Namely, only having support for
linear functions makes it a bit inconvenient to manipulate linear values
directly -- programs end up taking on a CPS-like structure. This seems to
remain an advantage of a direct implementation of linear types over the Linear
Haskell style.


\subsection{Simplicity and Further Work}

We are pleasantly surprised at how simple the overall design and implementation
of \lang\ is, given its expressive power and usability.  So simple in fact,
that fractions, a convenient theoretical abstraction until this point, could be
implemented by restricting division and multiplication to be by 2 only
\cite{boyland2003}, thus turning any required arithmetic into unification.

Indeed, the focus on getting a working prototype early on (so that we could
test it with real BLAS/LAPACK routines as soon as possible) meant that we only
added features to the type system when it was clear that they were absolutely
necessary: these features were !-types and value-restriction for the
\highl{Many} constructor. 

Going forwards, one may wish to eliminate even more runtime errors from \lang,
by extending its type system. For example, we could have used existential types
to statically track pointer identities~\cite{morrisett}, or parametric
polymorphism.

We could also attempt to catch mismatched dimensions at compile time as well.
While this could be done with generative phantom types~\cite{abe2015simple},
using dependent types may offer more flexibility in \emph{partitioning}
regions~\cite{space_monads} or statically enforcing dimensions related
constraints of the arguments at compile-time.  ATS~\cite{cui2005ats} is an
example of a language which combines linear types with a sophisticated proof
layer. But although it provides BLAS bindings, it does not aim to provide
aliasing restrictions as demonstrated in this paper.

Taking this idea one step even further, since matrix dimensions are typically
fixed at runtime, we could \emph{stage} \lang\ programs and compile matrix
expressions using more sophisticated algorithms~\cite{barthels}. However, it is
worth noting that without care, such algorithms~\cite{rocklin_thesis}, usually
based on graph-based, ad-hoc dataflow analysis, can produce erroneous output
which would not get past a linear type system with fractions.

We also think that this concept (and the general design of its implementation)
need not be limited to linear algebra: we could conceivably `backport' this
idea to other contexts that need linearity (concurrency, single-use
continuations, zero-copy buffer, streaming I/O) or combine it with dependent
types to achieve even more expressive power to split up a single block of
memory into multiple regions in an arbitrary manner~\cite{space_monads}.
