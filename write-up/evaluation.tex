\chapter{Evaluation}

% Least Squares Linear Regression
% p73 onwards https://people.cs.uchicago.edu/~mrocklin/storage/dissertation.pdf

\begin{guidance}
    For any practical projects, you should almost certainly have
    some kind of evaluation, and it's often useful to separate
    this out into its own chapter.
\end{guidance}

\prechapter{%
    I will evaluate the central premise of this thesis: linear types are a
    practical and usable tool to help working programmers write readable, safe
    (with respect to aliasing, read/write permissions, memory re-use and
    deallocation) and explicit (with respect to memory allocation) code that
    (1) is more memory-efficient than code written using purely high-level
    linear algebra libraries and (2) performs just as predictably as code
    written using low-level linear-algebra libraries. I will also elaborate on
    the qualitative benefits of using linearly types to write linear-algebra
    programs.
}%

\section{Set-up}

I analysed four implmentations of a Kalman filter, increasing
the abstraction level at each step:

\begin{enumerate}

    \item a CBLAS/LAPACKE implementation, handwritten in C
        (Figure~\ref{fig:cblas_kalman}), with a minimal number of temporaries,
        calls to `symm' for matrices known to be symmetric ahead of time,
        transposition passed in to `gemm' as a flag and Cholesky decomposition
        for multiplying by an inverse of a matrix

    \item a LT4LA implementation (Figure~\ref{fig:ltfla_kalman}), also with a
        minimal number of temporaries, calls to `symm' for matrices known to be
        symmetric ahead of time, transposition passed in to `gemm' as a flag
        and Cholesky decomposition for multiplying by an inverse of a matrix

    \item an Owl/OCaml implementation using a Cholesky decomposition
        (Figure~\ref{fig:chol_owl_kalman}) but not taking advantage of matrices
        known to be symmetric ahead of time, and producing a new temporary
        matrix for every operation (including inverse and tranpose)

    \item an idiomatic Owl/OCaml implmentation
        (Figure~\ref{fig:chol_owl_kalman}) with an explicit inverse (LU
        decomposition), not taking advantage of matrices known to be symmetric
        ahead of time, and producing a new temporary matrix for every operation
        (including inverse and tranpose).

\end{enumerate}

\begin{sidewaysfigure}

    \begin{minted}[linenos, fontsize=\small]{c}
static void kalman(
    const int n,               const int k,                const double *sigma, /* n,n */
    const double *h, /* k,n */ const double *mu, /* n,1 */ double *r,           /* k,k */
    double *data,    /* k,1 */ double **ret_mu,  /* k,1 */ double **ret_sigma   /* n,n */
) {
        double* k_by_n = (double *) malloc(k * n * sizeof(double));
/*20*/  cblas_dsymm(CblasRowMajor, CblasRight, CblasUpper, k, n, 1., sigma, n, h, n, 0., k_by_n, n);
/*21*/  cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasTrans, k, k, n, 1., k_by_n, n, h, n, 1., r, k);
/*22*/  cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, k, 1, n, 1., h, n, mu, 1, -1., data, 1);
/*23*/  cblas_dcopy(k * n, h, 1, k_by_n, 1);
        double* k_by_k = (double *) malloc(k * k * sizeof(double));
/*24*/  cblas_dcopy(k * k, r, 1, k_by_k, 1);
/*25*/  LAPACKE_dposv(LAPACK_ROW_MAJOR, 'U', k, n, k_by_k, k, k_by_n, n);
/*27*/  LAPACKE_dpotrs(LAPACK_ROW_MAJOR, 'U', k, 1, k_by_k, k, data, 1);
        free(k_by_k);
        double* n_by_n = (double *) malloc(n * n * sizeof(double));
/*28*/  cblas_dgemm(CblasRowMajor, CblasTrans, CblasNoTrans, n, n, k, 1., h, n, k_by_n, n, 0., n_by_n, n);
        free(k_by_n);
        double* n_by_1 = (double *) malloc(n * sizeof(double));
/*29*/  cblas_dgemm(CblasRowMajor, CblasTrans, CblasNoTrans, n, 1, k, 1., h, n, data, 1, 0., n_by_1, 1);
        double* new_mu = (double *) malloc(n * sizeof(double));
/*30*/  cblas_dcopy(n, mu, 1, new_mu, 1);
/*31*/  cblas_dsymm(CblasRowMajor, CblasLeft, CblasUpper, n, 1, 1., sigma, n, n_by_1, 1, 1., new_mu, 1);
        free(n_by_1);
        double* n_by_n2 = (double *) malloc(n * n * sizeof(double));
/*32*/  cblas_dsymm(CblasRowMajor, CblasRight, CblasUpper, n, n, 1., sigma, n, n_by_n, n, 0., n_by_n2, n);
/*33*/  cblas_dcopy(n*n, sigma, 1, n_by_n, 1);
/*34*/  cblas_dsymm(CblasRowMajor, CblasLeft, CblasUpper, n, n, -1., sigma, n, n_by_n2, n, 1., n_by_n, n);
        free(n_by_n2);
        *ret_sigma = n_by_n;
        *ret_mu = new_mu;
}
    \end{minted}
    \caption{CBLAS/LAPACKE implementation of a Kalman filter. I used C instead
        of Fortran because it is what Owl uses under the hood and OCaml FFI
        support for C is better and easier to use than that for Fortran. A distinct
        `measure\_kalman' function that sandwiches a call to this funtion with
        \texttt{getrusage} is omitted for brevity.}\label{fig:cblas_kalman}

\end{sidewaysfigure}

\begin{figure}[tp]
    \begin{minted}[linenos, fontsize=\small]{ocaml}
let potrs ~uplo a b =
  let b = Owl.Mat.copy b in
  Owl.Lapacke.potrs ~uplo ~a ~b
;;

let chol_kalman ~sigma ~h ~mu ~r ~data =
  let open Owl.Mat in
  let ( * ) = dot in
  let h' = transpose h in
  let sigma_h' = sigma * h' in
  let chol = Owl.Linalg.D.chol (r + h * sigma_h') in
  let sigma_h'_inv rest = sigma_h' * potrs ~uplo:'U' chol rest in
  let new_sigma = sigma - sigma_h'_inv (h * sigma) in
  let new_mu = mu + sigma_h'_inv (h * mu - data) in
  ((sigma, (h, (mu, (r, data)))), (new_mu, new_sigma))
;;

let owl_kalman ~sigma ~h ~mu ~r ~data =
  let open Owl.Mat in
  let ( * ) = dot in
  let h' = transpose h in
  let sigma_h' = sigma * h' in
  let x = sigma_h' * (inv @@ r + h * sigma_h') in
  let new_mu = mu + x * (h * mu - data) in
  let new_sigma = sigma - x * h * sigma in
  ((sigma, (h, (mu, (r, data)))), (new_mu, new_sigma))
;;
    \end{minted}
    \caption{Implementations of a Kalman filter using Owl, top one using a
        Cholesky decomposition, bottom one using idiomatic Owl. Owl does not
        yet provide a non-mutating `potrs' function, so I wrote my own which
        returns a mutated copy of its argument instead.}\label{fig:chol_owl_kalman}

\end{figure}

I evaluated the implmentations on two metrics: memory usage (via number and
size of temporaries allocated) and execution time. For the former, I compiled
Owl with print-statements on the relevant primitives to see exactly the number
of temporaries allocated for a single call of each function. While I did also
attempt to use gperftools and OCaml's profiling support with gprof for a more
holistic view of memory usage in the presence of OCaml's garbage-collector, I
ran into technical difficulties irrelevant to this thesis.

I measured execution time, in micro-seconds, against an exponentially (powers
of 5) increasing scaling factor for matrix size parameters $n=5$ and $k=3$.
For small scaling factors (1, 5, 25), I used the Core\_bench micro-benchmarking
library, for larger factors (125 and greater), I used the \texttt{getrusage}
system call (called \ltfla{Unix.times} in OCaml).  Core\_bench performs a
linear-regression (here, time against batch-size) so includes 95\%
confidence-interval with $R^2$. Larger scales have errors reported to $\pm
\sigma$ (one standard-deviation) 

\section{Results}

Raw output of implementation traces and the benchmarking program (including
sample sizes) for each of the implementations are in
Appendix~\ref{chap:eval_data}.

\subsection{Memory Usage}

Inspecting the Owl trace shows generated 11 temporary matrices (13 calls to
empty, 2 of which are the resulting matrices). Chol shows 13 temporaries (same
as Chol plus two temporaries for the two calls to potrs), whereas both LT4LA
and CBLAS have 4 temporaries. Analysing the sub-expressions of the Owl
implementation shows the total amount of memory allocated for temporaries is $n
+ n^2 + 4nk + 3k^2 + 2k$ words; for Chol the total is that of Owl plus $n +
nk$; for LT4LA and CBLAS the total is $n + n^2 + nk + k^2$.

\subsection{Execution Time}

A graph of the execution times (with error bars which are present but quite
small) is show in Figure~\ref{fig:timings}.

\begin{figure}[tp]
    \centering
    \input{timings.tex}
    \caption{Comparison of execution times. Small matrices and timings $n \le
        5^3$ were micro-benchmarked with the Core\_bench library. Larger ones used
    Unix's \texttt{getrusage} functionality.}\label{fig:timings}
\end{figure}

For $n=5$, and a per implementation sample size of around 450, the CBLAS
implementation is the fastest ($24\mu s$), followed by LT4LA ($41 \mu s$), then
Cholesky and Owl (around $52 \mu s$).  However, for $n=25$, and around 350
measurements per implementation, the idiomatic Owl implementation is the fastest
($95 \mu s$), \emph{then} CBLAS ($104 \mu s$), with LT4LA and Chol last (around
$130 \mu s$). The 95\% confidence-intervals around these measurements have been
between 0 and 2.

For $n=125$, and a per implementation sample size of around 110, the trends change:
CBLAS implmentation is now the \emph{slowest} ($1803 \mu s\, [1746,\, 1867]$).
This is followed by LT4LA ($1678 \mu s\, [1646,\, 1714]$) and Owl ($1488 \mu
s\, [1464,\, 1515]$). Chol had a low $R^2$ value ($0.74$) and so its execution
time is inconclusive here.

For $n=625$ and a sample size of 1000, Chol was now the fastest ($125.5 \pm
25\,ms$), then Owl ($146 \pm 32 \,ms$), followed by LT4LA ($180.5 \pm 38 \,ms$)
and CBLAS ($188 \pm 36 \, ms$). Despite the large sample size, the
standard-deviation is still quite high; however, calculating the pair-wise
$p$-values (Welch's t-test) suggests that the difference in the means is meaningful.

For $n=3125$, Chol takes approximately half the execution time ($11.4 \pm 2.7
\,s$) of the rest (differences between LT4LA, Owl and CBLAS were not
statistically significant, $p>.05$, using Welch's t-test) around $22s$.

\section{TO DO: Analysis}

Having access to primitives which allow a programmer to re-use memory means
that memory usage for temporaries in LT4LA is on par with that of C. One caveat
is that the `free\_mat' primitive is a no-op in LT4LA, which still relies on
OCaml's garbage-collector. The difference between these two implementations
and the idiomatic Owl implementation is $k(3n+2k+2)$ words, and 

\section{TO DO: Limitations}

\section{TO DO: Qualitative Benefits}

