\section{\lang\ Overview and Examples}\label{sec:lang_and_examples}

\subsection{Overview}

Linearity is at the heart of \lang. Linearity allows us to express a
pure-functional API for numerical library routines that mutate arrays and
matrices. Linearity also restricts aliasing of (values which represent)
pointers.

\subsubsection{Intuitionism: ! and \highl{Many}}

However, linearity by itself is not sufficient to produce an expressive enough
programming language. For values such as booleans, integers, floating-point
numbers as well as pure functions, we need to be able to use them
\emph{intuitionistically}, that is, more than once or not at all. For this
reason, we have the ! constructor at the type level and its corresponding
\highl{Many} constructor and \highl{let Many <id> = .. in ..} eliminator at
the term level. Because we want to restrict how a programmer can alias pointers
and prevent a programmer from ignoring them (a memory leak), \lang\ enforces
simple syntactic restrictions on which values can be wrapped up in a
\highl{Many} constructor (details in Section~\ref{sec:formal_system}).

\subsubsection{Fractional Permissions}

There are also valid cases in which we would want to alias pointers to a
matrix. The most common is exemplified by the BLAS routine \highl{gemm}, which
(rather tersely) stands for \emph{GEneric Matrix Multiplication}.  A
\emph{simplified} definition of \texttt{gemm($\alpha$, A, B, $\beta$, C)} is $C
:= \alpha AB + \beta C$. In this case, \texttt{A} and \texttt{B} may alias each
other but neither may alias \texttt{C}, because it is being written to.
Related to \emph{mutating} arrays and matrices is \emph{freeing} them. Here, we
would also wish to restrict aliasing so that we do not free one alias and then
attempt to use another. Although linearity on its own suffices to prevent
use-after-free errors when values are \emph{not} aliased (a freed value is
\emph{out of scope} for the rest of the expression), we still need another
simple, yet powerful concept to provide us with the extra expressivity of
aliasing \emph{without} losing any of the benefits of linearity.

Fractional permissions provide exactly this. Concretely, types of (pointers to)
arrays and matrices are \emph{parameterised} by a \emph{fraction}. A fraction
is either $1$ ($2^0$) or exactly \emph{half} of another fraction ($2^{-k}$, for
natural $k$). The former represents complete ownership of that value: the
programmer may mutate or free that value as they choose; the latter represents
read-only access or a \emph{borrow}: the programmer may read from the value but
not write to or free it. Creating an array/matrix gives you ownership of it, so
too does having one (with a fractional permission of $2^0$) passed in as an
argument.

In \lang, we can produce two aliases of a single array/matrix, by
\emph{sharing} it. If the original alias had a fractional permission of
$2^{-k}$ then the two new aliases of it will have a fractional permission of
$2^{-(k+1)}$ each. Thanks to linearity, the original array/matrix with a
fractional permission of $2^{-k}$ will be out of scope after the sharing.  When
an array/matrix is shared as such, we can prevent the programmer from freeing
or mutating it by making the types of \texttt{free} and \texttt{set} (for
mutation) require a \emph{whole} ($2^0$) permission.

If we have two aliases \emph{to the same matrix} with \emph{identical}
fractional permissions ($2^{-(k+1)}$), we can recombine or \emph{unshare} them
back into a single one, with a larger $2^{-k}$ permission. As before, thanks to
linearity, the original two aliases will be out of scope after unsharing.

\subsubsection{Runtime Errors}

Aside from out-of-bounds indexing, matrix unsharing is one of only \emph{two}
operations that can fail at runtime (the other being dimension checks, such as
for \texttt{gemm}). The check being performed is a simple sanity check that the
two aliasing pointers passed to \texttt{unshare} point to the same array/matrix.
Section~\ref{sec:discussion_related_work} contains an overview of how we could
remove the need for this by tracking pointer identities statically by
augmenting the type system further.

\subsubsection{Recursion}

The final feature of \lang\ which makes it sufficiently expressive is recursion
(and of course, conditional branches to ensure termination). Conditional
branches are implemented by ensuring that both branches use the same set of
linear values. A function can be recursive if it captures no linear values from
its environment. Like with \highl{Many}, this is enforced via simple syntactic
restrictions on the definition of recursive functions.

\subsection{Examples}

\subsubsection{Factorial}

Although a factorial function (Figure~\ref{fig:lang_factorial}) may seem like
an aggresively pedestrian first example, in a linearly typed language such as
\lang\ it represents the culmination of many features.

To simplifiy the design and implementation of \lang's type system, recursive
functions must have full type annotations (non-recursive functions need only
their argument types annotated). Its body is a closed expression (with respect
to the function's arguments), so it type-checks (since it does not capture any
linear values from its environment).

The only argument is \highl{!x : !int}. The ! annotation on \texttt{x} is a
syntactic convenience for declaring the value to used intuitionistically, its
full and precise meaning is described in Section~\ref{subsubsec:initial}.

The condition for an \highl{if} may or may not use linear values (here, with
\highl{x < 0 || x = 0}, it does not). Any linear values used by the condition
would not be in scope in either branch of the \highl{if}-expression.  Both
branches use \texttt{x} differently: one ignores it completely and the other
uses it twice.

All numeric and boolean literals are implicitly wrapped in a \highl{Many} and
all primitives involving them return a \highl{!int}, \highl{!bool} or
\highl{!elt} (types of elements of arrays/matrices, typically 64-bit
floating-point numbers). The short-circuting \texttt{||} behaves in exactly the
same way as a boolean-valued \highl{if}-expression.

\begin{figure}[t]
    \centering
    \inputminted[fontsize=\small, linenos]{ocaml}{../../examples/factorial.lt}
    \caption{Factorial function in \lang.}\label{fig:lang_factorial}
\end{figure}

\subsubsection{Summing over an Array}

Now we can add fractional permissions to the mix:
Figure~\ref{fig:lang_sumarray} shows a simple, tail-recursive implementation of
summing all the elements in an array. There are many new features; first among
them is \highl{!x0 : !elt}, the type of array/matrix elements (64-bit floating
point).

\begin{figure}[t]
    \centering
    \inputminted[fontsize=\small]{ocaml}{../../examples/sum_array.lt}
    \caption{Summing over an array in \lang.}\label{fig:lang_sumarray}
\end{figure}

Second is \highl{('x) (row: 'x arr)} which is an array with a
universally-quantified fractional permission. In particular, this means the
body of the function cannot mutate or free the input array, only read from it.
If the programmer did try to mutate or free \texttt{row}, then they would get a
helpful error message (Figure~\ref{fig:lang_errormsg}).

\begin{figure}[t]
    \centering
    \begin{minted}[fontsize=\small]{ocaml}
let row = row[i] := x1 in (* or *) let () = free row in
(* Could not show equality:                                        *)
(*     z arr                                                       *)
(* with                                                            *)
(*     'x arr                                                      *)
(*                                                                 *)
(* Var 'x is universally quantified                                *)
(* Are you trying to write to/free/unshare an array you don't own? *)
(* In examples/sum_array.lt, at line: 7 and column: 19        *)
    \end{minted}
    \caption{Attempting to write to or free a read only array in
    \lang.}\label{fig:lang_errormsg}
\end{figure}

Alongside taking a \highl{row: 'x arr}, the function also returns an array
with exactly the same fractional permission as the \texttt{row} (which can only
be \texttt{row}).  This is necessary because of linearity: for the caller, the
original array passed in as an argument would be out of scope for the rest of
the expression, so it needs to be returned and then rebound to be used for the
rest of the function.

An example of this consuming and re-binding is in \highl{let (row, !x1) =
row[i]}. Indexing is implemented as a primitive \highl{get: 'x. 'x arr --o
!int --o 'x arr * !elt}. Although fractional permissions can be passed around
explicitly  (as done in the recursive call), they can also be
\emph{automatically inferred at call sites}: \highl{row[i] == get _ row i}
takes advantage of this convenience.

\subsubsection{One-dimensional Convolution}

\begin{figure}[t]
    \centering
    \inputminted[fontsize=\small]{ocaml}{../../examples/weighted_avg_infer.lt}
    \caption{\emph{Simplified} one-dimensional convolution.}\label{fig:lang_oned_conv}
\end{figure}

Figure~\ref{fig:lang_oned_conv} extends the set of features demonstrated by the
previous examples by mutating one of the input arrays. A one-dimensional
convolution involves two arrays: a read-only kernel (array of weights) and an
input vector. It modifies the input vector \emph{in-place} by replacing each
\highl{write[i]} with a weighted (as per the values in the kernel) sum of it
and its neighbours; intuitively, sliding a dot-product with the kernel across
the vector.

What's implemented in Figure~\ref{fig:lang_oned_conv} is a \emph{simplified}
version of this idea, so as to not distract from the features of \lang. The
simplifications are:
\begin{itemize}
    \item the kernel has a length 3, so only the value of \highl{write[i-1]}
        (prior to modification in the previous iteration) needs to be carried
        forward using \highl{x0}
    \item \highl{write} is assumed to have length \highl{n+1}
    \item \texttt{i}'s initial value is assumed to be \texttt{1}
    \item \highl{x0}'s initial value is assumed to be \highl{write[0]}
    \item the first and last values of \texttt{write} are ignored.
\end{itemize}

Mutating an array is implemented similarly to indexing one: a primitive
\highl{set: z arr --o !int --o !elt --o z arr}.  It consumes the original
array and returns a new array with the updated value.  \highl{let written =
write[i] := <exp> } is just syntactic sugar for \highl{let written = set write i <exp>}.

Since \highl{write: z arr} (where \texttt{z} stands for $k=0$, representing a
fractional permission of $2^{-k} = 2^{-0} = 1$), we may mutate it, but since we
only need to read from \texttt{weights}, its fractional permission index can be
universally-quantified. In the recursive call, we see \texttt{\_} being used
explicitly to tell the compiler to \emph{infer} the correct fractional
permission based on the given arguments.

\subsubsection{Squaring a Matrix}

\begin{figure}[t]
    \centering
    \inputminted[fontsize=\small]{ocaml}{../../examples/square.lt}
    \caption{Linear regression (OLS): $\hat\beta =
        \mathbf{(X^T X)^{-1} X^T y}$}\label{fig:lang_square}
\end{figure}

\emph{The most pertinent aspect of \lang\ is the types of its primitives.}
While the types of operations such as \texttt{get} and \texttt{set} might be
borderline obvious, the types of BLAS/LAPACK routines become an
\emph{incredibly useful, automated check for using the API correctly.}

Figure~\ref{fig:lang_square} shows how a linearly-typed matrix squaring
function may be written in \lang. It is a \emph{non-recursive} function
declaration (the return type is inferred). Since we would like to be able to
use a function like \texttt{square} more than once, it is marked with a
\texttt{!} annotation (which also ensures it captures no linear values from the
surrounding environment).

To square a matrix, first, we extract the dimensions of the argument
\texttt{x}. Then, because we need to use \texttt{x} twice (so that we can
multiply it by itself) but linearity only allows one use, we use \highl{shareM:
'x. 'x mat --o 'x s mat * 'x s mat} to split the permission \texttt{'x} (which
represents $2^{-x}$) into two halves (\texttt{'x s}, which represents $2^{-(x+1)}$).

Even if \texttt{x} had type \texttt{z mat}, sharing it now enforces the
assumption of all BLAS/LAPACK routines that any matrix which is written to
(which, in \lang, is always of type \texttt{z mat}) does not alias any other
matrix in scope. So if we did try to use one of the aliases in mutating way,
the expression would not type check, and we would get an error similar to the
one in Figure~\ref{fig:lang_errormsg}.

The line \highl{let answer <- new (m,n) [| x1 * x2 |]} is syntactic sugar for
first creating a new $m \times n$ matrix (\highl{let answer = matrix m n}) and
then storing the result of the multiplication in it (\highl{let ((x1, x2),
answer) = gemm 1. _ (x1, false) _ (x2, false) 0. answer}). \highl{false} means
the matrix should not be accessed with indices transposed.

By using some simple pattern-matching and syntactic sugar, we can:
\begin{itemize}
    \item write normal-looking, apparently non-linear code
    \item use matrix expressions directly and have a call to an efficient
        call to a BLAS/LAPACK routine inserted with appropriate re-bindings
    \item retain the safety of linear types with fractional permissions by
        having the compiler statically enforce the aliasing and read/write rules
        implicitly assumed by BLAS/LAPACK routines.
\end{itemize}

\subsubsection{Linear Regression}

\begin{figure}[t]
    \centering
    \inputminted[fontsize=\small]{ocaml}{../../examples/lin_reg.lt}
    \caption{Linear regression (OLS): $\hat\beta =
        \mathbf{(X^T X)^{-1} X^T y}$}\label{fig:lang_lin_reg}
\end{figure}

In Figure~\ref{fig:lang_lin_reg}, we wish to compute $\hat\beta = \mathbf{(X^T
X)^{-1} X^T y}$. To do that, first, we extract the dimensions of matrix
\texttt{x}. Then, we say we would like \texttt{xy} to be a new matrix, of
dimension $m \times 1$, which contains the result of $\mathbf{X^T y}$ (using
syntactic sugar for \texttt{matrix} and \texttt{gemm} calls similar to that
used in Figure~\ref{fig:lang_square}, with a \highl{^T} annotation on
\texttt{x} to set \texttt{x}'s `transpose indices'-flag to \highl{true}).

However, the line \highl{let x_T_x <- new (m,m) [| x^T * x |]}, works for a
slightly different reason: that pattern is matched to a BLAS call to
(\highl{syrk true 1.  x 0. x_T_x}), which only uses \texttt{x} once. Hence
\texttt{x} can appear \emph{twice} in the \emph{pattern} without any calls to
\texttt{share}.

After computing \texttt{x\_T\_x}, we need to invert it and then multiply it by
\texttt{xy}. The BLAS routine \highl{posv: z mat --o z mat --o z mat * z mat}
does exactly that: assuming the first argument is symmetric, \texttt{posv}
mutates its second argument to contain the desired value. Its first argument is
also mutated to contain the (upper triangular) Cholesky decomposition factor of
the original matrix. Since we do not need that matrix (or its memory) again, we
\texttt{free} it. If we forgot to, we would get a \texttt{Variable to\_del not
used} error. Lastly, we return the \texttt{answer} alongside the untouched
input matrices \texttt{(x,y)}.

\subsubsection{L1-Norm Minimisation on Manifolds}

L1-Norm minimisation is often used in optimisation problems, as a
\emph{regularisation} term for reducing the influence of outliers.  Although
the below formuation\cite{bronstein} is intended to be used with \emph{sparse}
computations, \lang's current implementation only implements dense ones.
However, it still serves as a useful example of explaining \lang's features.

\begin{figure}[t]
    \centering
    \inputminted[fontsize=\small]{ocaml}{../../examples/l1_norm_min.lt}
    \caption{L1-norm minimisation on manifolds:
        $\mathbf{Q^{-1}U(I+U^TQ^{-1}U)^{-1}U^T}$}\label{fig:lang_l1_norm_min}
\end{figure}

Figure~\ref{fig:lang_l1_norm_min} shows even more pattern-matching. Patterns of
the form \highl{let <id> <- [| beta * c + alpha * a * b |]} are also desugared to
\texttt{gemm} calls. Primitives like \highl{transpose: 'x. 'x mat --o 'x mat *
z mat} and \highl{eye: !int --o z mat} allocate new matrices;
\texttt{transpose} returns the transpose of a given matrix and \texttt{eye k}
evaluates to a $k \times k$ identity matrix.

We also see our first example of re-using memory for different matrices: like
with \texttt{to\_del} and \texttt{posv} in the previous example, we do not need
the value stored in \texttt{tmp\_5\_5} after the call to \texttt{gesv} (a
primitive similar to \texttt{posv} but for a non-symmetric first argument).
However, we can re-use its memory much later to store \texttt{answer} with
\highl{let answer <- [| 0. * tmp_5_5 + q_inv_u * inv_u_T |]}. Again, thanks to
linearity, the identifiers \texttt{q} and \texttt{tmp\_5\_5} are out of scope
by the time \texttt{answer} is bound. Although during execution, all three
refer to the same piece of memory, logically they represent different values
throughout the computation.

\subsubsection{Kalman Filter}

A \emph{Kalman Filter}\cite{kalman} is a an algorithm for combining prior
knowledge of a state, a statistical model and measurements from (noisy) sensors
to produce an estimate a more reliable estimated of the current state.  It has
various applications (navigation, signal-processing, econometrics) and is
relevant here because it is usually presented as a series of complex matrix
equations.

\begin{figure}[t]
    \centering
%   \begin{minipage}{.4\textwidth}
%   \centering
    \inputminted[fontsize=\small]{ocaml}{../../examples/kalman.lt}
%   \end{minipage}
%   \begin{minipage}{.4\textwidth}
%   \centering
%   \begin{minted}[linenos,fontsize=\small]{ocaml}
%   let owl_kalman
%       ~sigma
%       ~h
%       ~mu
%       ~r
%       ~data =
%     let open Owl.Mat in
%     let ( * ) = dot in
%     let h' = transpose h in
%     let sigma_h' = sigma * h' in
%     let x = sigma_h' * (inv @@ r + h * sigma_h') in
%     let new_mu = mu + x * (h * mu - data) in
%     let new_sigma = sigma - x * h * sigma in
%     new_sigma, new_mu
%   ;;
%   \end{minted}
%   \end{minipage}
    \caption{Kalman filter: see Figure~\ref{fig:kalman_eqns} for the
        equations this code implements. Line numbers in comments refer to
        equivalent lines in a C implementation
        (Figure~\ref{fig:cblas_kalman}).}\label{fig:lang_kalman}
\end{figure}

\begin{figure}[t]
    % align* uses too much vertical space
    {\centering
    $  \displaystyle
    \begin{aligned}
        \mu' &= \mu + \Sigma H^T (R + H \Sigma H^T)^{-1} (H \mu - \textrm{data})\\
        \Sigma' &= \Sigma ( I - H^T (R + H \Sigma H^T)^{-1} H \Sigma )
    \end{aligned}
    $ \par}
    \caption{Kalman filter equations (credit:
    \href{http://matthewrocklin.com/blog/work/2012/11/24/Kalman-Filter}{matthewrocklin.com}).}\label{fig:kalman_eqns}
\end{figure}

Figure~\ref{fig:lang_kalman} shows a \lang\ implementation of a Kalman filter
(equations in Figure~\ref{fig:kalman_eqns}). A few new features and techniques
are used in this implementation:
\begin{itemize}

    \item \texttt{sym} annotations in matrix expressions: when this is used, a 
        call to \texttt{symm} (the equivalent of \texttt{gemm} but for
        symmetric matrices so that only half the operations are performed) is
        inserted

    \item \texttt{copyM\_to} is used to re-use memory by \emph{overwriting} the
        contents of its second argument to that of its first (erroring if
        dimensions do not match)

    \item \highl{let new_r <- new [| r_2 |]} creates a copy of \texttt{r\_2}

    \item \texttt{posvFlip} is like \texttt{posv} except for solving $XA = B$

    \item a lot of memory re-use; the following sets of identifiers alias each other:
        \begin{itemize}
            \item \texttt{r\_1}, \texttt{r\_2} and \texttt{k\_by\_k}
            \item \texttt{data\_1} and \texttt{data\_2}
            \item \texttt{mu} and \texttt{new\_mu}
            \item \texttt{sigma\_hT} and \texttt{x}
        \end{itemize}

\end{itemize}

The \lang\ implementation is much longer than the mathematical equations for
two reasons. First, the \lang\ implementation is a let-normalised form of the
Kalman equations: since there a large number of unary/binary (and occasionally
ternary) sub-expressions in the equations, naming each one line at a time makes
the implementation much longer.  Second, \lang\ has the additional task of
handling explicit allocations, aliasing and frees of matrices. However, it is
exactly this which makes it possible (and often, easy) to spot additional
opportunities for memory re-use. Furthermore, a programmer can explore those
opportunities easily because \lang's type system statically enforces correct
memory management and the aliasing assumptions of BLAS/LAPACK routines.

